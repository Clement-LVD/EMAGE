---
date:  "2023-03-12T00:00:00Z"
# le filename en fait c'est dans le asset/media folder qu'il va chercher l'image !
external_link: ""
image:
  filename: "/couv/text_mining_supervise.png"
  # caption: Principaux th√®mes du site, d'apr√®s la [section "tags"](/#tag_cloud)
  focal_point: Smart
# links:
# - icon: linkedin
#   icon_pack: fab
#   name: Connect
#   url: https://www.linkedin.com/in/cl√©ment-laverdet-503879188
# slides: example
summary: M√©thode par lexiques, **sans erreur et reproductible**. Pour analyser de petits ensembles de texte efficacement.
tags:
- Text-analysis
- Analyse th√©matique supervis√©e
- Lexiques
categories: 
- Analyse de textes
- R√©seaux de relations
- Enqu√™tes
title: Analyse th√©matique supervis√©e par des lexiques
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""
---
<!--Les textes sont g√©n√©ralement constitu√©s de plusieurs th√©matiques. L'analyse th√©matique vise notamment √† identifier ces th√©matiques et √† caract√©riser la composition d'un ensemble de textes (pr√©sence ou absence des diff√©rentes th√©matiques).-->

<div style="background-color: black"> <img src="/logos/emage_texte_mining_supervise.gif" style= "float: left" width="140px" > 
 

> <aaa style="color: white"> <strong> üéØ Cet article pr√©sente une m√©thode d'analyse th√©matique supervis√©e par des lexiques. Cette m√©thode vise √† cat√©goriser un ensemble 'restreints' de textes: quelques dizaines d'entretiens retranscrits, ou encore quelques centaines de textes de quelques phrases renseign√©s dans des questionnaires, dans les posts Facebook des concurrents, des commentaires en ligne, etc. </strong> </aaa> </div>



{{% callout note %}}
La construction de lexiques sur-mesure permet de cat√©goriser les textes de fa√ßon tr√®s fiable, en garantissant que l'int√©gralit√© du texte est cat√©goris√©e et en minimisant les erreurs. 
{{% /callout %}}

{{% callout warning %}}
Cette m√©thode "manuelle" de construction de lexiques n'est pas envisageable avec de gros ensembles de textes ou des textes tr√®s longs.
{{% /callout %}}


# Avantages de la m√©thode
**L'approche par lexique permet de garder trace des cat√©gorisations r√©alis√©es, pour :**

- [x] **Relire les lexiques et v√©rifier les cat√©gorisations efficacement** 
    - [x] en se concentrant seulement sur les bouts de textes pertinents,
    - [x] en ayant la possibilit√© d'en discuter √† plusieurs,
    - [x] etc.
- [x] **Impliquer plusieurs codeurs / relecteurs efficacement**
- [x] **Produire des annexes et des d√©tails au sujet des formulations les plus utilis√©es**
- [x] **√âviter les sur-interpr√©tations, les cat√©gorisations √©tant *strictement* r√©alis√©es d'apr√®s une liste de termes et de paraphrases**
- [x] **Garantir la cat√©gorisation de l'ensemble du texte**
    - [x] en confrontant le texte "capt√©" dans les lexiques et le texte qu'il reste √† cat√©goriser au fur-et-√†-mesure de la construction des lexiques,
    - [x] et en terminant l'analyse avec un lexique des √©l√©ments non-pertinents (e.g., des √©lements contextuels sans rapport avec l'objet d'√©tude)
- [x] **Capitaliser chaque lexique**, voir superviser l'attribution de th√©matiques d'apr√®s des lexiques constitu√©s dans de pr√©c√©dents projets (fonctionne surtout pour les lexiques peu h√©t√©rog√®nes comme les fa√ßons de d√©signer un v√©hicule par exemple)
- [x] et bien d'autres avantages...

# Constituer les lexiques
Il y a plusieurs √©tapes, entre la premi√®re lecture des textes et la cat√©gorisation de l'int√©gralit√© du contenu dans des lexiques.


<figure> <figcaption> Processus de constitution de lexiques et de validation </figcaption>

```mermaid
sequenceDiagram 
TEXTES->>LEXIQUES: 1 - Constitution des lexiques <br>
Note left of LEXIQUES: Les lexiques se construisent d'abord<br> autour des termes les plus fr√©quents

loop
# LEXIQUES-->>TEXTES: 
LEXIQUES-->>TEXTES: 2 - V√©rifications des cat√©gorisations<br>et identification des textes non-int√©gr√©s aux lexiques,<br>jusqu'√† cat√©goriser l'ensemble du texte  
Note left of LEXIQUES: Y compris un lexique d'√©lements non-retenus pour l'analyse<br>(e.g., d√©tails contextuels non-pertinents) 
    LEXIQUES-->>LEXIQUES: 3 - Relectures des lexiques<br>Pertinence des cat√©gorisations ?
 end

# Note left of LEXIQUES: << Possibilit√©s de validation crois√©e<br>des attributions r√©alis√©es >>

LEXIQUES-->TEXTES: L'ensemble du texte est cat√©goris√© d'apr√®s les lexiques <br>‚Üì G√©n√©ration d'un bilan ‚Üì
# LEXIQUES->>Relecteurs ext√©rieurs: 4. Avis des relecteurs ?
# Relecteurs ext√©rieurs-->>LEXIQUES: 5. Discussions ==> et au final "Super !"
```
<figcaption> Ce processus permet une validation par le client, des relectures crois√©es, etc. </figcaption>
</figure>

Au final, chaque texte est cat√©goris√© d'apr√®s la pr√©sence ou l'absence des diff√©rentes th√©matiques, c'est-√†-dire la pr√©sence ou l'absence de termes pr√©cis, recens√©s dans diff√©rents lexiques. 

<figure> <figcaption> Repr√©sentation de la cat√©gorisation r√©alis√©e (pr√©sence ou absence des th√©matiques) </figcaption>

```markmap
- Corpus initial
  - TEXTE ‚Ö†
    - ‚òë Th√®me 1
      - ‚òë Sous-th√®me 1.A
      - ‚òí `Sous-th√®me 1.B`
    - ‚òë Th√®me 2
    - ‚òí `Th√®me 3`
    - ‚òë Th√®me 4
      - ‚òí `Sous-th√®me 4.A`
      - ‚òë Sous-th√®me 4.B
      - ‚òë Sous-th√®me 4.C
    - *(Th√®mes 5, 6, etc.)*
  - TEXTE ‚Ö°
    - ‚òë Th√®me 1
      - ‚òí `Sous-th√®me 1.A`
      - ‚òë Sous-th√®me 1.B
    - ‚òí  `Th√®me 2`
    - ‚òë Th√®me 3
    - ‚òë Th√®me 4
      - ‚òí `Sous-th√®me 4.A`
      - ‚òí `Sous-th√®me 4.B`
      - ‚òë Sous-th√®me 4.C
    - *(Th√®mes 5, 6, etc.)*
  - TEXTES ‚Ö¢, ‚Ö£, etc.
```

</figure>

{{< spoiler text="Pour r√©aliser les lexiques, j'utilise des expressions r√©guli√®res ou RegEx (le langage informatique sp√©cialis√© dans la manipulation, la s√©lection ou l'identification de textes)." >}}
Les RegEx permettent:

- de gagner du temps (e.g., en d√©clinant plusieurs fa√ßons d'√©crire le m√™me terme en une br√®ve syntaxe unique);

- de superviser les caract√©risations r√©alis√©es, par exemple pour distinguer les parties-prenantes (e.g., "***je*** roulais trop vite" vs. "***il*** roulait trop vite").
{{< /spoiler >}}


On peut ensuite r√©aliser des statistiques descriptives pour pr√©senter les textes, typiquement en d√©taillant les th√©matiques les plus pr√©gnantes dans les textes, celles qui coexistent entre elles - √©ventuellement syst√©matiquement, etc. 

# Exemples
Cette m√©thode d'analyse par lexiques √† √©t√© d√©ploy√© pour mieux comprendre les facteurs des accidents de la route. L'analyse par lexiques concernait des textes explicatifs de situations accidentog√®nes et d'accidents, renseign√©s par des personnes impliqu√©es dans de telles situations pendant leurs trajets en voiture, en v√©lo, √† pied, en trottinette √©lectrique, etc. Un exemple d'article universitaire mobilisant cette m√©thode est en cours de publication. Ci-ensuite, un exemple de recherche universitaire mobilisant cette m√©thode d'analyse par lexiques (pr√©sentation √† la conf√©rence IRTAD 2022 - [itf-oecd.org](https://www.itf-oecd.org/7th-irtad-conference-better-road-safety-data-better-safety-outcomes)). 

<embed src= "https://www.itf-oecd.org/sites/default/files/repositories/typology_of_risky_situations.pdf"  type="application/pdf" width="100%" height="600px" />

## Inconv√©nients de cette m√©thode
Le temps de constitution des lexiques augmente avec la longeur du texte qu'il faut cat√©goriser. Pour cat√©goriser un nombre important de textes, la m√©thode pr√©sent√©e dans cet article devrait "seulement" se concentrer sur un √©chantillon de ces textes. Pour cat√©goriser des ensembles importants de textes, il faut √©galement exploiter des m√©thodes plus globales, non-supervis√©es (e.g., GloVe[^2]) ou m√™me supervis√©es (e.g., fasttext[^1]). 

[^1]: https://fasttext.cc/

[^2]: https://nlp.stanford.edu/pubs/glove.pdf

